{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory Assignment 1: Counting Words\n",
    "\n",
    "**This is the first of three mandatory assignments to be handed in as part of the assessment for the course 02807 Computational Tools for Data Science at Technical University of Denmark, autumn 2019.**\n",
    "\n",
    "#### Practical info\n",
    "- **The assignment is to be done individually. You are under no circumstances allowed to collaborate with anyone on solving the exercises (cf. the full policy on this on the course website)**\n",
    "- **You must hand in one Jupyter notebook (this notebook) with your solution**\n",
    "- **The hand-in of the notebook is due 2019-10-13, 23:59 on DTU Inside**\n",
    "\n",
    "#### Your solution\n",
    "- **Your solution should be in Python**\n",
    "- **For each question you should use exactly the cells provided for your solution**\n",
    "- **You should not remove the problem statements, and you should not modify the structure of the notebook**\n",
    "- **Your notebook should be runnable, i.e., clicking [>>] in Jupyter should generate the result that you want to be assessed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction\n",
    "In this assignment you will build data structures for counting words in a text. Suppose you are given a very large corpus of text, and from time to time you need to count how many times a word occurs. You could write a program that searches the text from start to end every time you want to make a query, but for large texts, this will be very slow. A common way to handle this, is to preprocess the text into a data structure that contains exactly the information needed to answer specific queries like the frequency of a word.\n",
    "\n",
    "Given a text, you should build data structures that can answer the following questions efficiently:\n",
    "- How many times does a given word occur in the text? (exercise 2)\n",
    "- How many times in total does a word starting with a given prefix occur? (exercise 3)\n",
    "\n",
    "For each of these questions you should write a function that organizes data in a way (the data structure) that makes it possible to write an efficient function (the query) to answer the questions. A good data structure is one where the query is much faster than just searching the text while still is not using too much space.\n",
    "\n",
    "You should not use any Python libraries (except `string`!) to solve the exercises. You may use build-ins like lists, dictionaries, `map`, `filter`, and so on.\n",
    "\n",
    "You should provide implementations for the functions in this notebook. Do not change the names of the functions.\n",
    "\n",
    "To test your programs, we will use the complete works of William Shakespeare. Please run the cells below to load the text and show a preview. You should be online before you do this. Note that a good solution will have to work for even larger texts than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "text = requests.get('https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the 100th Etext file presented by Project Gutenberg, and\n",
      "is presented in cooperation with World Library, Inc., from their\n",
      "Library of the Future and Shakespeare CDROMS.  Project Gutenberg\n",
      "often releases Etexts that are NOT placed in the Public Domain!!\n",
      "\n",
      "Shakespeare\n",
      "\n",
      "*This Etext has certain copyright implications you should read!*\n",
      "\n",
      "<<THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM\n",
      "SHAKESPEARE IS COPYRIGHT 1990-1993 BY WORLD LIBRARY, INC., AND IS\n",
      "PROVIDED BY PROJECT GUTENBERG ETEXT OF ILLINOIS BENEDICTINE COLLEGE\n",
      "WITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE\n",
      "DISTRIBUTED SO LONG AS SUCH COPIES (1) ARE FOR YOUR OR OTHERS\n",
      "PERSONAL USE ONLY, AND (2) ARE NOT DISTRIBUTED OR USED\n",
      "COMMERCIALLY.  PROHIBITED COMMERCIAL DISTRIBUTION INCLUDES BY ANY\n",
      "SERVICE THAT CHARGES FOR DOWNLOAD TIME OR FOR MEMBERSHIP.>>\n",
      "\n",
      "*Project Gutenberg is proud to cooperate with The World Library*\n",
      "in the presentation of The Complete Works of William Shakespeare\n",
      "for your reading for educatio ...\n"
     ]
    }
   ],
   "source": [
    "print('{} ...'.format(text[0:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 1\n",
    "In this exercise you should create a helper function for parsing a text into an iterable (e.g., a list) of words. You will need this in the subsequent exercises.\n",
    "\n",
    "You should make sure that:\n",
    "- each element of the iterable is exactly one word,\n",
    "- all words are lower case,\n",
    "- words do not contain punctuation.\n",
    "\n",
    "Write a function `text_to_words()` that takes as input a string and output an iterable of the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def text_to_words(text):\n",
    "    \n",
    "    # Map all punctuation characters to 'None'\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    # Remove punctuation characters from the string and do lowercase\n",
    "    text = text.translate(translator).lower()\n",
    "    # Split the string\n",
    "    words = text.split()\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should output 'this is a test'\n",
    "' '.join(text_to_words('THIS is, a test!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text_to_words(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 2\n",
    "In this exercise you should create a data structure that can give an answer to the following query.\n",
    "- How many times does a given word occur in the text?\n",
    "\n",
    "You should do the following:\n",
    "- Write a function `build_word_count_data_structure()` that takes as input an iterable of strings, and outputs a data structure for looking up how many times a string occurs.\n",
    "\n",
    "- Write a function `get_word_count()` that uses your data structure to count the number of times a word occurs.\n",
    "\n",
    "- Explain with words how your data is organized in your data structure, how your function constructs it, and how a query works. Why is it efficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_word_count_data_structure(words):\n",
    "    \n",
    "    # Create a dict to save the number of occurrences per word\n",
    "    word_occurrences = {}\n",
    "    # Check every word of the text\n",
    "    for word in words:\n",
    "        try:\n",
    "            # Try to increment the number of occurrences for a word\n",
    "            word_occurrences[word] += 1\n",
    "        except KeyError:\n",
    "            # A 'KeyError' exception raises if the word had not been detected yet:\n",
    "            # Initialize the count for the word\n",
    "            word_occurrences[word] = 1\n",
    "    \n",
    "    return word_occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = build_word_count_data_structure(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_count(ds, word):\n",
    "    return ds[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_count(ds, 'romeo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "Two different implementations have been contemplated to get the number of occurences of each word in the text efficiently:\n",
    "1. Use a dictionary to save the number of occurrences for a word. Then iterate the word array and use the function 'text.count(word)' to count the occurrences within the text. If the word has been analized previously (is already stored in the dictionary) just avoid to repeat the counting process.\n",
    "2. A similar process than the previous one, but just avoiding using the function 'text.count(word)'. Instead of it, just increase by 1 the number of occurrences every time the word is detected. If the word is still not stored in the dictionary the count will be initialized to 1.\n",
    "\n",
    "Some implementations, like using the 'filter()' function to find the occurrences, have been discarded because they localize their computational cost in the 'get_word_count()' function, while executing the search and not previously (in the 'build_word_count_data_structure()' function). It's better to process the data only one time and then get the required information in a quick way than process it every time a query is performed.\n",
    "\n",
    "Other implementations were discarded due to their complexity, such as try to organize the words by the letters to avoid iterating all the words. However, create complex structures to store data implies the design of ways to recover all the words in an efficient way.\n",
    "\n",
    "Finally the two selected methods were tested. The first one took over 370secs to finish and the second one only 0,15secs, so the first one was discarted. Just before finish a last improvement was tested with the final method: instead of check if a word is allready stored in the dictionary just try to increment its count. If an exception is raised (because the word is still not stored) catch it and initialize the count of the word to 1. With this last change the execution time finally was only 0,11secs.\n",
    "\n",
    "**Why is it efficient?**\n",
    "\n",
    "In the first method the function 'text.count(word)' is being executed one time per each different word in the text. This function seems to works well with small strings but is slow while working with big ones (as the text used in this exercise). The second method is very simple and very efficient because it only needs to iterate the words' array and not analyze the entire text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 3\n",
    "In this exercise you should create a data structure that can give an answer to the following query.\n",
    "- How many times in total does a word starting with a given prefix occur?\n",
    "\n",
    "For example, `bar` is a prefix of `bar`, `barracuda`, and `barrier`, and the result of the query should include the sum of the number of times each of those words occur.\n",
    "\n",
    "You should do the following:\n",
    "- Write a function `build_prefix_count_data_structure()` that takes as input a list of strings, and outputs a data structure for looking up how many times a prefix occurs in words.\n",
    "\n",
    "- Write a function `get_prefix_count()` that uses your data structure to count the number of times a prefix occurs.\n",
    "\n",
    "- Explain with words how your data is organized in your data structure, how your function constructs it, and how a query works. Why is it efficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prefix_count_data_structure(words):\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = build_prefix_count_data_structure(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prefix_count(ds, prefix):\n",
    "    \n",
    "    # Create an integer to count the number of words with the prefix\n",
    "    count = 0\n",
    "    # Check every word of the text\n",
    "    for word in ds:\n",
    "        # Increment by 1 if the word starts with the prefix\n",
    "        if (word.startswith(prefix)):\n",
    "            count += 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "852"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prefix_count(ds, 'rom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "The data structure containing the words from the test is the same one used in the previous exercise (no changes made to the array in the function 'build_prefix_count_data_structure()').\n",
    "\n",
    "Three different methods have been tested to get the number of words in a text containing a prefix:\n",
    "1. A simple loop with a counter incremented by 1 if the word starts with the prefix, using the function 'word.startswith(prefix)'.\n",
    "2. Use the 'filter()' function to get all the words containing the prefix and then just get the length of the result.\n",
    "3. Almost equal to the first method mentioned but checking the beggining letters of the words by one instead of using the 'word.startswith(prefix)' function.\n",
    "\n",
    "With the same prefix \"rom\" the first method only took 0,1sec to finish, meanwhile the second and the third method needed 0,2 and 0,3sec respectively. The analyzed text is very long so the performance is good for all of them, although the first method is the most efficient one and is the one being used in this notebook.\n",
    "\n",
    "**Why is it efficient?**\n",
    "\n",
    "The '.startswith()' seems to be very well optimized and is a better option compared to checking the characters one by one. Also the 'filter()' function is very useful to manage the data but seems to be a bit slower than the process used in the first method.\n",
    "\n",
    "The problem here, compared to the previous exercise, is that the computational cost is located when retrieving the number of words with a prefix and not while creating the data structure to save the information. To be able to avoid the computational cost in the 'get_prefix_count()' it's necessary to implement some complex system to tokenize the words within the array (as search engines do)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
